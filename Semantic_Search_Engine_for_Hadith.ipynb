{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GKnOeK5CY57",
        "outputId": "03b0cb98-619b-40f0-8c9a-fd633a36cd25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers flask pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro8ZqwCICiR9",
        "outputId": "b6a862e6-4002-433b-bef4-3a73d803f644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "hadith-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  hadith-dataset.zip\n",
            "replace all_hadiths_clean.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!echo '{\"username\":\"ramaalyoubi\",\"key\":\"82e22c4988257fba9141f3be474f0b66\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d fahd09/hadith-dataset\n",
        "!unzip hadith-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc2nj0Neluej",
        "outputId": "7782af07-c710-4b2b-bb42-d05e3b075b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f2nceSpDPuR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from langdetect import detect\n",
        "import re\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('all_hadiths_clean.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zX8UYWsIhK5",
        "outputId": "8f69a749-ad57-4490-8cd2-0a72317251d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-09c1759b031e>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['text_en'] = df['text_en'].str.lower().str.replace('[^\\w\\s]', '')\n"
          ]
        }
      ],
      "source": [
        "# Normalize the text\n",
        "df['text_en'] = df['text_en'].str.lower().str.replace('[^\\w\\s]', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaO1XqPIIbec"
      },
      "outputs": [],
      "source": [
        "# Check for missing values and handle them\n",
        "df.dropna(subset=['text_ar', 'text_en'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXqYvA6jjoZm"
      },
      "outputs": [],
      "source": [
        "from langdetect import detect, LangDetectException\n",
        "\n",
        "def remove_english_words(chapter_name):\n",
        "    # Split the chapter name into Arabic and English parts\n",
        "    parts = chapter_name.split(' and ')\n",
        "\n",
        "    # Filter out the Arabic part\n",
        "    arabic_part = parts[0]\n",
        "\n",
        "    # Remove any remaining English words using regex\n",
        "    cleaned_chapter_name = re.sub(r'\\b\\w+\\b', '', arabic_part).strip()\n",
        "\n",
        "    return cleaned_chapter_name\n",
        "\n",
        "# Apply function to remove English words from chapter names\n",
        "df[\"chapter\"] = df[\"chapter\"].apply(lambda x: remove_english_words(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjO4repijGBZ"
      },
      "outputs": [],
      "source": [
        "# Define dataset class\n",
        "class HadithDataset(Dataset):\n",
        "    def __init__(self, texts, chapters, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.chapters = chapters\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        chapter = self.chapters[idx]\n",
        "        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': torch.tensor(chapter)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FmOEAktjG-k"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into train and validation sets\n",
        "train_texts, val_texts, train_chapters, val_chapters = train_test_split(df['text_ar'], df['chapter'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CjptupjDVPT"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/aragpt2-base\")\n",
        "model = AutoModel.from_pretrained(\"aubmindlab/aragpt2-base\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3akOfuwojdMv",
        "outputId": "ec89e401-5f13-4b11-f484-53bef2f0a479"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2Model(\n",
              "  (wte): Embedding(64000, 768)\n",
              "  (wpe): Embedding(1024, 768)\n",
              "  (drop): Dropout(p=0.1, inplace=False)\n",
              "  (h): ModuleList(\n",
              "    (0-11): 12 x GPT2Block(\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): GPT2Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): GPT2MLP(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (act): NewGELUActivation()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define dataset and dataloaders\n",
        "train_dataset = HadithDataset(train_texts.tolist(), train_chapters.tolist(), tokenizer, max_length=128)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "val_dataset = HadithDataset(val_texts.tolist(), val_chapters.tolist(), tokenizer, max_length=128)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baYuJ0GpDX5n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Function to encode text to embeddings using the last hidden state of the model\n",
        "def encode_text_with_labels(texts, labels, model, tokenizer, max_length=None, batch_size=32):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_embeddings = []\n",
        "    all_labels = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        batch_labels = labels[i:i+batch_size] # Ignore this step\n",
        "        encoded_input = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='pt', max_length=max_length).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**encoded_input)\n",
        "            # Get the embeddings from the last hidden state\n",
        "            embeddings = outputs.last_hidden_state[:, -1, :].detach().cpu().numpy()\n",
        "            all_embeddings.append(embeddings)\n",
        "            all_labels.extend(batch_labels)\n",
        "\n",
        "    # Concatenate all batch embeddings\n",
        "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
        "    return all_embeddings, all_labels\n",
        "\n",
        "# Define a padding token for the tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "batch_size = 32\n",
        "max_length = 256\n",
        "# Generate embeddings for each Hadith without labels\n",
        "embeddings, _ = encode_text_with_labels(df['text_ar'].tolist(), df['chapter'].tolist(), model, tokenizer, max_length=max_length, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDBRECPUDZ-I"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def semantic_search(query, embeddings, texts, tokenizer, model, top_k=5):\n",
        "    # Encode the query to get its embedding\n",
        "    query_embedding = encode_text_with_labels([query], [None], model, tokenizer)[0]\n",
        "    # Calculate cosine similarity scores\n",
        "    scores = cosine_similarity(query_embedding.reshape(1, -1), embeddings)\n",
        "    # Get the indices of the top-k most similar texts\n",
        "    top_k_indices = scores.argsort(axis=1)[:, ::-1][:, :top_k]\n",
        "    # Get the texts and their corresponding scores\n",
        "    results = [(texts[i], scores[0, i]) for i in top_k_indices[0]]\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNV6cskXDani",
        "outputId": "3cf4faa9-97fb-40dc-ce6a-8a124ea0b996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query: جد لي حديث عن أهمية الصلاة\n",
            "Score: 0.5251553654670715, Hadith: أخبرنا محمد بن بشار، قال حدثنا يحيى بن سعيد، عن هشام، عن قتادة، ح وأنبأنا محمد بن المثنى، قال حدثنا يحيى، قال حدثنا هشام، قال حدثنا قتادة، عن يونس بن جبير، عن حطان بن عبد الله، أن الأشعري، قال إن رسول الله صلى الله عليه وسلم خطبنا فعلمنا سنتنا وبين لنا صلاتنا فقال ‏\"‏ إذا قمتم إلى الصلاة فأقيموا صفوفكم ثم ليؤمكم أحدكم فإذا كبر فكبروا وإذا قال ‏{‏ ولا الضالين ‏}‏ فقولوا آمين يجبكم الله ثم إذا كبر وركع فكبروا واركعوا فإن الإمام يركع قبلكم ويرفع قبلكم ‏\"‏ ‏.‏ قال نبي الله صلى الله عليه وسلم ‏\"‏ فتلك بتلك وإذا قال سمع الله لمن حمده فقولوا اللهم ربنا لك الحمد فإن الله عز وجل قال على لسان نبيه صلى الله عليه وسلم سمع الله لمن حمده ثم إذا كبر وسجد فكبروا واسجدوا فإن الإمام يسجد قبلكم ويرفع قبلكم ‏\"‏ ‏.‏ قال نبي الله صلى الله عليه وسلم ‏\"‏ فتلك بتلك وإذا كان عند القعدة فليكن من قول أحدكم أن يقول التحيات الطيبات الصلوات لله السلام عليك أيها النبي ورحمة الله وبركاته السلام علينا وعلى عباد الله الصالحين أشهد أن لا إله إلا الله وأشهد أن محمدا عبده ورسوله ‏\"‏ ‏.‏\n",
            "Score: 0.4532153308391571, Hadith: حدثني حرملة بن يحيى، أخبرني ابن وهب، أخبرني يونس، ح وحدثني أبو الطاهر، ومحمد بن سلمة المرادي قالا حدثنا ابن وهب، عن يونس، عن ابن شهاب، قال أخبرني عروة بن الزبير، عن عائشة، زوج النبي صلى الله عليه وسلم قالت خسفت الشمس في حياة رسول الله صلى الله عليه وسلم فخرج رسول الله صلى الله عليه وسلم إلى المسجد فقام وكبر وصف الناس وراءه فاقترأ رسول الله صلى الله عليه وسلم قراءة طويلة ثم كبر فركع ركوعا طويلا ثم رفع رأسه فقال ‏\"‏ سمع الله لمن حمده ربنا ولك الحمد ‏\"‏ ‏.‏ ثم قام فاقترأ قراءة طويلة هي أدنى من القراءة الأولى ثم كبر فركع ركوعا طويلا هو أدنى من الركوع الأول ثم قال ‏\"‏ سمع الله لمن حمده ربنا ولك الحمد ‏\"‏ ‏.‏ ثم سجد - ولم يذكر أبو الطاهر ثم سجد - ثم فعل في الركعة الأخرى مثل ذلك حتى استكمل أربع ركعات وأربع سجدات وانجلت الشمس قبل أن ينصرف ثم قام فخطب الناس فأثنى على الله بما هو أهله ثم قال ‏\"‏ إن الشمس والقمر آيتان من آيات الله لا يخسفان لموت أحد ولا لحياته فإذا رأيتموها فافزعوا للصلاة ‏\"‏ ‏.‏ وقال أيضا ‏\"‏ فصلوا حتى يفرج الله عنكم ‏\"‏ ‏.‏ وقال رسول الله صلى الله عليه وسلم ‏\"‏ رأيت في مقامي هذا كل شىء وعدتم حتى لقد رأيتني أريد أن آخذ قطفا من الجنة حين رأيتموني جعلت أقدم - وقال المرادي أتقدم - ولقد رأيت جهنم يحطم بعضها بعضا حين رأيتموني تأخرت ورأيت فيها ابن لحى وهو الذي سيب السوائب ‏\"‏ ‏.‏ وانتهى حديث أبي الطاهر عند قوله ‏\"‏ فافزعوا للصلاة ‏\"‏ ‏.‏ ولم يذكر ما بعده ‏.‏\n",
            "Score: 0.4231443703174591, Hadith: حدثنا أحمد بن منيع، حدثنا هشيم، أخبرنا ابن أبي ليلى، عن الشعبي، قال صلى بنا المغيرة بن شعبة فنهض في الركعتين فسبح به القوم وسبح بهم فلما صلى بقية صلاته سلم ثم سجد سجدتى السهو وهو جالس ثم حدثهم أن رسول الله صلى الله عليه وسلم فعل بهم مثل الذي فعل ‏.‏ قال وفي الباب عن عقبة بن عامر وسعد وعبد الله ابن بحينة ‏.‏ قال أبو عيسى حديث المغيرة بن شعبة قد روي من غير وجه عن المغيرة بن شعبة ‏.‏ قال أبو عيسى وقد تكلم بعض أهل العلم في ابن أبي ليلى من قبل حفظه ‏.‏ قال أحمد لا يحتج بحديث ابن أبي ليلى ‏.‏ وقال محمد بن إسماعيل ابن أبي ليلى هو صدوق ولا أروي عنه لأنه لا يدري صحيح حديثه من سقيمه وكل من كان مثل هذا فلا أروي عنه شيئا ‏.‏ وقد روي هذا الحديث من غير وجه عن المغيرة بن شعبة رواه سفيان عن جابر عن المغيرة بن شبيل عن قيس بن أبي حازم عن المغيرة بن شعبة ‏.‏ وجابر الجعفي قد ضعفه بعض أهل العلم تركه يحيى بن سعيد وعبد الرحمن بن مهدي وغيرهما ‏.‏ والعمل على هذا عند أهل العلم أن الرجل إذا قام في الركعتين مضى في صلاته وسجد سجدتين منهم من رأى قبل التسليم ومنهم من رأى بعد التسليم ‏.‏ ومن رأى قبل التسليم فحديثه أصح لما روى الزهري ويحيى بن سعيد الأنصاري عن عبد الرحمن الأعرج عن عبد الله ابن بحينة ‏.‏\n",
            "Score: 0.41822952032089233, Hadith: حدثنا أحمد بن حنبل، حدثنا الوليد بن مسلم، حدثنا الأوزاعي، حدثني يحيى، - يعني ابن أبي كثير - عن أبي سلمة، عن أبي هريرة، قال لما فتح الله تعالى على رسول الله صلى الله عليه وسلم مكة قام رسول الله صلى الله عليه وسلم فيهم فحمد الله وأثنى عليه ثم قال ‏\"‏ إن الله حبس عن مكة الفيل وسلط عليها رسوله والمؤمنين وإنما أحلت لي ساعة من النهار ثم هي حرام إلى يوم القيامة لا يعضد شجرها ولا ينفر صيدها ولا تحل لقطتها إلا لمنشد ‏\"‏ ‏.‏ فقام عباس أو قال قال العباس يا رسول الله إلا الإذخر فإنه لقبورنا وبيوتنا ‏.‏ فقال رسول الله صلى الله عليه وسلم ‏\"‏ إلا الإذخر ‏\"‏ ‏.‏ قال أبو داود وزادنا فيه ابن المصفى عن الوليد فقام أبو شاه - رجل من أهل اليمن - فقال يا رسول الله اكتبوا لي ‏.‏ فقال رسول الله صلى الله عليه وسلم ‏\"‏ اكتبوا لأبي شاه ‏\"‏ ‏.‏ قلت للأوزاعي ما قوله ‏\"‏ اكتبوا لأبي شاه ‏\"‏ ‏.‏ قال هذه الخطبة التي سمعها من رسول الله صلى الله عليه وسلم ‏.‏\n",
            "Score: 0.4080915153026581, Hadith: حدثنا هناد، حدثنا أبو معاوية، عن الأعمش، قال وحدثنا محمود بن غيلان، حدثنا أبو معاوية، وعبد الله بن نمير، عن الأعمش، عن إسماعيل بن رجاء الزبيدي، عن أوس بن ضمعج، قال سمعت أبا مسعود الأنصاري، يقول قال رسول الله صلى الله عليه وسلم ‏\"‏ يؤم القوم أقرؤهم لكتاب الله فإن كانوا في القراءة سواء فأعلمهم بالسنة فإن كانوا في السنة سواء فأقدمهم هجرة فإن كانوا في الهجرة سواء فأكبرهم سنا ولا يؤم الرجل في سلطانه ولا يجلس على تكرمته في بيته إلا بإذنه ‏\"‏ ‏.‏ قال محمود بن غيلان قال ابن نمير في حديثه ‏\"‏ أقدمهم سنا ‏\"‏ ‏.‏ قال أبو عيسى وفي الباب عن أبي سعيد وأنس بن مالك ومالك بن الحويرث وعمرو بن سلمة ‏.‏ قال أبو عيسى وحديث أبي مسعود حديث حسن صحيح ‏.‏ والعمل على هذا عند أهل العلم ‏.‏ قالوا أحق الناس بالإمامة أقرؤهم لكتاب الله وأعلمهم بالسنة ‏.‏ وقالوا صاحب المنزل أحق بالإمامة ‏.‏ وقال بعضهم إذا أذن صاحب المنزل لغيره فلا بأس أن يصلي به ‏.‏ وكرهه بعضهم وقالوا السنة أن يصلي صاحب البيت ‏.‏ قال أحمد بن حنبل وقول النبي صلى الله عليه وسلم ‏\"‏ ولا يؤم الرجل في سلطانه ولا يجلس على تكرمته في بيته إلا بإذنه ‏\"‏ ‏.‏ فإذا أذن فأرجو أن الإذن في الكل ولم ير به بأسا إذا أذن له أن يصلي به ‏.‏\n"
          ]
        }
      ],
      "source": [
        "query = input(\"Enter your query: \")\n",
        "# Use the query to perform semantic search\n",
        "results = semantic_search(query, embeddings, df['text_ar'].tolist(), tokenizer, model, top_k=5)\n",
        "# Display the results\n",
        "for text, score in results:\n",
        "    print(f\"Score: {score}, Hadith: {text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QHhcOeVJ2YF"
      },
      "outputs": [],
      "source": [
        "# Save the entire model\n",
        "torch.save(model, 'model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLP2CxhAOrPM"
      },
      "outputs": [],
      "source": [
        "# save only the model state dictionary\n",
        "torch.save(model.state_dict(), '/content/model_state_dict.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}